"""
–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å MoE (Mixture of Experts)
–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
"""

# ====================== –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö ======================
import tensorflow as tf
from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dense, Dropout, 
                                   BatchNormalization, Activation, GlobalAveragePooling2D,
                                   Add, Reshape, Multiply, Layer, LayerNormalization,
                                   RandomRotation, RandomZoom, RandomContrast, RandomBrightness,
                                   RandomFlip, RandomCrop, RandomSaturation)
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.regularizers import l1_l2
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, Callback
from tensorflow.keras.mixed_precision import set_global_policy
from tensorflow.keras import backend as K
import os
import numpy as np
from sklearn.utils.class_weight import compute_class_weight
import tf2onnx
import onnxruntime as ort
import math

# ========================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==========================
class Config:
    # -------------------- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ --------------------
    input_shape = (224, 224, 3)    # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (H, W, C)
    l1_value = 1e-6                # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç L1-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    l2_value = 1e-5                # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    dropout_rate = 0.5             # –ü—Ä–æ—Ü–µ–Ω—Ç –¥—Ä–æ–ø–∞—É—Ç–∞
    num_experts = 8                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ —Å–ª–æ–µ MoE
    expert_units = 1024            # –ù–µ–π—Ä–æ–Ω–æ–≤ –≤ –∫–∞–∂–¥–æ–º —ç–∫—Å–ø–µ—Ä—Ç–µ
    se_reduction = 16              # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤ SE-–±–ª–æ–∫–µ

    # --------------------- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è ---------------------
    initial_learning_rate = 1e-2   # –ù–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    batch_size = 32                # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    epochs = 1500                  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —ç–ø–æ—Ö
    min_learning_rate = 1e-10      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    reduce_lr_factor = 0.1         # –§–∞–∫—Ç–æ—Ä —É–º–µ–Ω—å—à–µ–Ω–∏—è LR
    reduce_lr_patience = 2         # –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è LR
    early_stopping_patience = 10   # –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    focal_gamma = 4                # –ü–∞—Ä–∞–º–µ—Ç—Ä Focal Loss (—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞)
    class_weight_gamma = 2         # –£—Å–∏–ª–µ–Ω–∏–µ –≤–ª–∏—è–Ω–∏–µ –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–∞

    # --------------------- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---------------------
    rotation_range = 0.4           # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞ (–¥–æ–ª—è –æ—Ç 180¬∞)
    zoom_range = 0.4               # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ/—É–º–µ–Ω—å—à–µ–Ω–∏–µ
    contrast_range = 0.4           # –î–∏–∞–ø–∞–∑–æ–Ω –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
    saturation_range = 0.4         # –î–∏–∞–ø–∞–∑–æ–Ω –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞—Å—ã—â–µ–Ω–æ—Å—Ç–∏
    brightness_range = 0.4         # –î–∏–∞–ø–∞–∑–æ–Ω –∏–∑–º–µ–Ω–µ–Ω–∏—è —è—Ä–∫–æ—Å—Ç–∏
    horizontal_flip = True         # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ
    vertical_flip = False          # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ
    validation_split = 0.2         # –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    augment_seed = 123             # –°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π

    # --------------------- –ü—É—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ---------------------
    source_dir = "/media/alex/Programs/NeuralNetwork/DataSet/ARTS/Original"
    checkpoint_path = "/media/alex/Programs/NeuralNetwork/Model/best_model.keras"
    labels_path = "/media/alex/Programs/NeuralNetwork/Model/labels.txt"
    onnx_path = "/media/alex/Programs/NeuralNetwork/Model/model.onnx"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = Config()
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)
tf.config.optimizer.set_experimental_options({
    "layout_optimizer": True,
    "constant_folding": True,
    "shape_optimization": True,
    "remapping": True,
    "arithmetic_optimization": True,
    "dependency_optimization": True,
    "loop_optimization": True,
    "function_optimization": True,
    "debug_stripper": True,
    "disable_meta_optimizer": False,
    "scoped_allocator_optimization": True,
    "pin_to_host_optimization": True,
    "auto_parallel" : True
})
set_global_policy('mixed_float16')  # –ê–∫—Ç–∏–≤–∞—Ü–∏—è mixed precision
tf.config.optimizer.set_jit(True)

# ====================== –ö–ê–°–¢–û–ú–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ ======================
class MoE(Layer):
    def __init__(self, num_experts=8, expert_units=4096, **kwargs):
        super().__init__(**kwargs)
        self.num_experts = num_experts
        self.expert_units = expert_units

    def build(self, input_shape):
        self.experts = [self._build_expert(input_shape[-1]) for _ in range(self.num_experts)]
        self.router = Dense(
            self.num_experts,
            activation='softmax',
            kernel_regularizer=l1_l2(config.l1_value, config.l2_value)
        )
        super().build(input_shape)

    def _build_expert(self, input_dim):
        return tf.keras.Sequential([
            Dense(self.expert_units, 
                  activation='swish',
                  kernel_regularizer=l1_l2(config.l1_value, config.l2_value)),
            Dropout(config.dropout_rate),
            Dense(input_dim,
                  kernel_regularizer=l1_l2(config.l1_value, config.l2_value))
        ])

    def call(self, inputs, training=None):
        # –ü–æ–ª—É—á–∞–µ–º –ª–æ–≥–∏—Ç—ã –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏
        logits = self.router(inputs)
        
        # –í–µ—Å–∞ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ —á–µ—Ä–µ–∑ softmax (—Ç–∏–ø: float16)
        weights = K.softmax(logits)
        
        # –ú–∞—Å–∫–∞ –¥–ª—è —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–í–ê–ñ–ù–û: –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Ç–∏–ø—É weights!)
        expert_mask = K.cast(
            weights > 0.1,        # –ë—É–ª–µ–≤ —Ç–µ–Ω–∑–æ—Ä
            dtype=weights.dtype   # –Ø–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ç–∏–ø –∫–∞–∫ —É weights (float16)
        )
        
        # –í—ã—Ö–æ–¥—ã —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —ç–∫—Å–ø–µ—Ä—Ç—ã –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç float16)
        expert_outputs = tf.stack([expert(inputs) for expert in self.experts], axis=1)
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ (—Ç–∏–ø—ã weights –∏ expert_mask —Ç–µ–ø–µ—Ä—å —Å–æ–≤–ø–∞–¥–∞—é—Ç)
        weighted_outputs = tf.einsum('be,beu->bu', weights * expert_mask, expert_outputs)
        
        return weighted_outputs + inputs

    def get_config(self):
        config = super().get_config()
        config.update({
            'num_experts': self.num_experts,
            'expert_units': self.expert_units
        })
        return config

    @classmethod
    def from_config(cls, config):
        return cls(**config)

def focal_loss(y_true, y_pred):
    y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())
    
    # 1. –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è –¥–ª—è –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
    ce = -y_true * K.log(y_pred)  # [batch, num_classes]
    ce = K.sum(ce, axis=-1)       # [batch,] (—Å—É–º–º–∞ —Ç–æ–ª—å–∫–æ –ø–æ –∞–∫—Ç–∏–≤–Ω–æ–º—É –∫–ª–∞—Å—Å—É)
    
    # 2. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∏—Å—Ç–∏–Ω–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞
    p_t = K.sum(y_true * y_pred, axis=-1)  # [batch,]
    
    # 3. –ú–æ–¥—É–ª—è—Ç–æ—Ä gamma
    modulator = K.pow(1. - p_t, config.focal_gamma)  # [batch,]
    
    # 4. –ò—Ç–æ–≥–æ–≤—ã–π loss (—É–∂–µ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å [batch,])
    loss = modulator * ce
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –±–∞—Ç—á—É (–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –¥–ª—è Keras)
    return K.mean(loss)

def se_block(input_tensor):
    channels = input_tensor.shape[-1]
    se = GlobalAveragePooling2D()(input_tensor)
    se = Reshape((1, 1, channels))(se)
    se = Dense(channels//config.se_reduction, activation='swish',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(se)
    se = Dense(channels, activation='sigmoid',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(se)
    return Multiply()([input_tensor, se])

def residual_block(x, filters, stride=1):
    shortcut = x
    if stride != 1 or shortcut.shape[-1] != filters:
        shortcut = Conv2D(filters, (1,1), strides=stride,
                          kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(shortcut)
        shortcut = BatchNormalization()(shortcut)
    
    x = Conv2D(filters, (3,3), strides=stride, padding='same',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(x)
    x = BatchNormalization()(x)
    x = Activation('swish')(x)
    x = Conv2D(filters, (3,3), padding='same',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(x)
    x = BatchNormalization()(x)
    x = se_block(x)
    return Activation('swish')(Add()([x, shortcut]))

# ====================== –ü–û–°–¢–†–û–ï–ù–ò–ï –ú–û–î–ï–õ–ò ======================
def build_model(num_classes):
    inputs = Input(shape=config.input_shape)
    
    # –ë—ç–∫–±–æ–Ω CNN
    x = Conv2D(64, (7,7), strides=2, padding='same',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(inputs)
    x = BatchNormalization()(x)
    x = Activation('swish')(x)
    x = MaxPooling2D((3,3), strides=2, padding='same')(x)
    
    # Residual Blocks
    x = residual_block(x, 64)
    x = residual_block(x, 64)
    x = residual_block(x, 128, stride=2)
    x = residual_block(x, 256, stride=2)
    x = residual_block(x, 512, stride=2)
    x = residual_block(x, 512)
    
    # –ì–æ–ª–æ–≤–Ω–∞—è —á–∞—Å—Ç—å
    x = GlobalAveragePooling2D()(x)
    x = LayerNormalization()(x)
    x = Dense(2048, activation='swish',
              kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(x)
    x = Dropout(config.dropout_rate)(x)
    x = MoE(config.num_experts, config.expert_units)(x)
    
    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)
    
    model = Model(inputs, outputs, name='AnimeClassifier')
    optimizer = SGD(learning_rate=config.initial_learning_rate,
                    momentum=0.95, 
                    nesterov=True)
    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
    model.compile(optimizer=optimizer,
                  loss=focal_loss,
                  metrics=['accuracy', 'precision', 'recall', 'auc', 'top_k_categorical_accuracy'])
    return model

# ====================== –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• ======================
def create_dataset(subset):
    return tf.keras.utils.image_dataset_from_directory(
        config.source_dir,
        labels='inferred',
        label_mode='categorical',
        color_mode='rgb',
        batch_size=config.batch_size,
        image_size=config.input_shape[:2],
        validation_split=config.validation_split,
        subset=subset,
        seed=config.augment_seed,
        shuffle=(subset == 'training')
    )

class EpochSpacingCallback(Callback):
    def on_epoch_end(self, epoch, logs=None):
        print('\n' + '=' * 100 + '\n')

# ====================== –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ======================
def run_training():
    os.makedirs(os.path.dirname(config.checkpoint_path), exist_ok=True)
    train_ds_raw = create_dataset('training')
    val_ds_raw = create_dataset('validation')
    num_classes = len(train_ds_raw.class_names)
    save_labels(train_ds_raw.class_names)

    # –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    def static_preprocessing(image, label):
        image = tf.cast(image, tf.float32) / 255.0
        return image, label

    augmentations = tf.keras.Sequential([
        RandomRotation(config.rotation_range),
        RandomZoom(config.zoom_range),
        RandomContrast(config.contrast_range),
        RandomBrightness(config.brightness_range),
        RandomFlip('horizontal'),
        RandomCrop(config.input_shape[0], config.input_shape[1]),  # –°–ª—É—á–∞–π–Ω–∞—è –æ–±—Ä–µ–∑–∫–∞
        RandomSaturation(config.saturation_range),  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∞—Å—ã—â–µ–Ω–Ω–æ—Å—Ç–∏
    ])

    train_ds = (
        train_ds_raw
        .map(lambda x, y: (augmentations(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)  # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è
        .map(static_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        .prefetch(tf.data.AUTOTUNE)
    )

    val_ds = (
        val_ds_raw
        .map(static_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        .prefetch(tf.data.AUTOTUNE)
    )

    # –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
    labels = np.concatenate([y.numpy().argmax(axis=1) for x, y in train_ds_raw], axis=0)
    total_samples = len(labels)
    class_counts = np.bincount(labels)
    class_weights = (total_samples / (len(np.unique(labels)) * class_counts)) ** config.class_weight_gamma
    class_weights = class_weights.astype(np.float32)
    class_weights_dict = {i: w for i, w in enumerate(class_weights)}

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    if os.path.exists(config.checkpoint_path):
        model = load_model(
            config.checkpoint_path,
            custom_objects={
                'MoE': MoE,
                'focal_loss': focal_loss,
                'LayerNormalization': LayerNormalization
            }
        )
        if model.output_shape[-1] != num_classes:
            raise ValueError("–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤!")
    else:
        model = build_model(num_classes)
        model.summary()

    callbacks = [
        ReduceLROnPlateau(monitor='val_loss', factor=config.reduce_lr_factor,
                         patience=config.reduce_lr_patience, min_lr=config.min_learning_rate),
        ModelCheckpoint(config.checkpoint_path, save_best_only=True, monitor='val_loss'),
        EarlyStopping(monitor='val_loss', patience=config.early_stopping_patience),
        EpochSpacingCallback()
    ]

    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=config.epochs,
        callbacks=callbacks,
        class_weight=class_weights_dict
    )
    return model

# ====================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ======================
def save_labels(class_names):
    with open(config.labels_path, "w") as f:
        for label in class_names: f.write(label + "\n")

def convert_to_onnx():
    model = load_model(
        config.checkpoint_path,
        custom_objects={
            'MoE': MoE,
            'focal_loss': focal_loss,
            'LayerNormalization': LayerNormalization
        }
    )
    input_signature = [tf.TensorSpec(shape=[None, *config.input_shape], dtype=tf.float32)]
    tf2onnx.convert.from_keras(model, input_signature=input_signature, output_path=config.onnx_path)
    check_onnx_work()

def check_onnx_work():
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤
    train_ds = tf.keras.utils.image_dataset_from_directory(
        config.source_dir,
        image_size=config.input_shape[:2],
        batch_size=config.batch_size,
        shuffle=False
    )
    class_names = train_ds.class_names
    with open(config.labels_path, 'w') as f:
        f.write('\n'.join(class_names))

    # –ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏
    session = ort.InferenceSession(config.onnx_path)
    input_name = session.get_inputs()[0].name

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ
    img_path = "test.jpg"

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
    img = tf.keras.preprocessing.image.load_img(img_path)
    img_array = tf.keras.preprocessing.image.img_to_array(img)

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    img_array = tf.expand_dims(img_array, 0) / 255.0 # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0,1]
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_path}")
    print(f"–§–æ—Ä–º–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {img_array.shape}")

    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    results = session.run(None, {input_name: img_array.numpy().astype(np.float32)})
    probabilities = results[0][0]
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    top5_indices = np.argsort(probabilities)[::-1][:5]
    top5_classes = [class_names[i] for i in top5_indices]
    top5_probs = [probabilities[i] for i in top5_indices]

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüîÆ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ onnx:")
    for cls, prob in zip(top5_classes, top5_probs):
        print(f"  {cls}: {prob*100:.2f}%")

    model = load_model(
        config.checkpoint_path,
        custom_objects={
            'MoE': MoE,
            'focal_loss': focal_loss,
            'LayerNormalization': LayerNormalization
        }
    )

    results = model.predict(img_array)

    probabilities = results[0]
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    top5_indices = np.argsort(probabilities)[::-1][:5]
    top5_classes = [class_names[i] for i in top5_indices]
    top5_probs = [probabilities[i] for i in top5_indices]

    print("\nüîÆ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ keras:")
    for cls, prob in zip(top5_classes, top5_probs):
        print(f"  {cls}: {prob*100:.2f}%")

# ====================== –ò–ù–¢–ï–†–§–ï–ô–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ======================
def main():
    while True:
        print("\n–ú–µ–Ω—é:\n1. –û–±—É—á–∏—Ç—å\n2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å\n3. –¢–µ—Å—Ç ONNX\nexit. –í—ã—Ö–æ–¥")
        choice = input("–í—ã–±–æ—Ä: ").strip()
        if choice == '1':
            run_training()
        elif choice == '2':
            convert_to_onnx()
        elif choice == '3':
            check_onnx_work()
        elif choice == 'exit':
            break

if __name__ == "__main__":
    main()