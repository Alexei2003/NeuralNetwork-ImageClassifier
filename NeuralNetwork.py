"""
–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–∞—è –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å MoE (Mixture of Experts)
–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–æ–≤
"""

# ====================== –ò–ú–ü–û–†–¢ –ë–ò–ë–õ–ò–û–¢–ï–ö ======================
import tensorflow as tf
from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dense, Dropout, 
                                   BatchNormalization, Activation, GlobalAveragePooling2D,
                                   Add, Reshape, Multiply, Layer, LayerNormalization,
                                   RandomRotation, RandomZoom, RandomContrast, RandomBrightness)
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.regularizers import l1_l2
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping, Callback
from tensorflow.keras.mixed_precision import set_global_policy
from tensorflow.keras import backend as K
import os
import numpy as np
from sklearn.utils.class_weight import compute_class_weight
import tf2onnx
import onnxruntime as ort
import matplotlib.pyplot as plt
import math

# ========================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==========================
class Config:
    # -------------------- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ --------------------
    input_shape = (224, 224, 3)    # –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (H, W, C)
    l1_value = 1e-5                # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç L1-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    l2_value = 1e-4                # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
    dropout_rate = 0.5             # –ü—Ä–æ—Ü–µ–Ω—Ç –¥—Ä–æ–ø–∞—É—Ç–∞
    num_experts = 4                # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–∫—Å–ø–µ—Ä—Ç–æ–≤ –≤ —Å–ª–æ–µ MoE
    expert_units = 2048            # –ù–µ–π—Ä–æ–Ω–æ–≤ –≤ –∫–∞–∂–¥–æ–º —ç–∫—Å–ø–µ—Ä—Ç–µ
    se_reduction = 16              # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É–º–µ–Ω—å—à–µ–Ω–∏—è –≤ SE-–±–ª–æ–∫–µ

    # --------------------- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è ---------------------
    initial_learning_rate = 1e-1   # –ù–∞—á–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    batch_size = 32                # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
    epochs = 1000                  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —ç–ø–æ—Ö
    min_learning_rate = 1e-10      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
    reduce_lr_factor = 0.25        # –§–∞–∫—Ç–æ—Ä —É–º–µ–Ω—å—à–µ–Ω–∏—è LR
    reduce_lr_patience = 1         # –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è LR
    early_stopping_patience = 10   # –¢–µ—Ä–ø–µ–Ω–∏–µ –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
    focal_alpha = 0.25             # –ü–∞—Ä–∞–º–µ—Ç—Ä Focal Loss (–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤)
    focal_gamma = 2.0              # –ü–∞—Ä–∞–º–µ—Ç—Ä Focal Loss (—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–∞)

    # --------------------- –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö ---------------------
    rotation_range = 0.2           # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —É–≥–æ–ª –ø–æ–≤–æ—Ä–æ—Ç–∞ (–¥–æ–ª—è –æ—Ç 180¬∞)
    zoom_range = 0.3               # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ/—É–º–µ–Ω—å—à–µ–Ω–∏–µ
    contrast_range = 0.2           # –î–∏–∞–ø–∞–∑–æ–Ω –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
    brightness_range = 0.3         # –î–∏–∞–ø–∞–∑–æ–Ω –∏–∑–º–µ–Ω–µ–Ω–∏—è —è—Ä–∫–æ—Å—Ç–∏
    horizontal_flip = True         # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ
    vertical_flip = False          # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ
    validation_split = 0.2         # –î–æ–ª—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    augment_seed = 123             # –°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π

    # --------------------- –ü—É—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è ---------------------
    source_dir = "/media/alex/Programs/NeuralNetwork/DataSet/ARTS/Original"
    checkpoint_path = "/media/alex/Programs/NeuralNetwork/Model/best_model.keras"
    labels_path = "/media/alex/Programs/NeuralNetwork/Model/labels.txt"
    onnx_path = "/media/alex/Programs/NeuralNetwork/Model/model.onnx"

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = Config()

# ====================== –ö–ê–°–¢–û–ú–ù–´–ï –ö–û–ú–ü–û–ù–ï–ù–¢–´ ======================
class MoE(Layer):
    def __init__(self, num_experts=8, expert_units=1024, **kwargs):  # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä
        super().__init__(**kwargs)
        self.num_experts = num_experts
        self.expert_units = expert_units

    def build(self, input_shape):
        self.experts = [self._build_expert(input_shape[-1]) for _ in range(self.num_experts)]
        self.router = Dense(
            self.num_experts,
            activation='softmax',
            kernel_regularizer=l1_l2(config.l1_value, config.l2_value)
        )
        super().build(input_shape)

    def _build_expert(self, input_dim):
        return tf.keras.Sequential([
            Dense(self.expert_units, 
                  activation='swish',
                  kernel_regularizer=l1_l2(config.l1_value, config.l2_value)),
            Dropout(config.dropout_rate),
            Dense(input_dim,
                  kernel_regularizer=l1_l2(config.l1_value, config.l2_value))
        ])

    def call(self, inputs):
        weights = self.router(inputs)
        expert_outputs = tf.stack([expert(inputs) for expert in self.experts], axis=1)
        weighted_outputs = tf.einsum('be,beu->bu', weights, expert_outputs)
        return weighted_outputs + inputs

    def get_config(self):
        config = super().get_config()
        config.update({
            'num_experts': self.num_experts,
            'expert_units': self.expert_units
        })
        return config

    @classmethod
    def from_config(cls, config):
        return cls(**config)

def focal_loss(y_true, y_pred):
    """Focal Loss –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–µ—Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –∫–ª–∞—Å—Å–∞–º–∏"""
    y_pred = K.clip(y_pred, K.epsilon(), 1. - K.epsilon())
    cross_entropy = -y_true * K.log(y_pred)
    loss = config.focal_alpha * K.pow(1. - y_pred, config.focal_gamma) * cross_entropy
    return K.sum(loss, axis=1)

def se_block(input_tensor):
    """Squeeze-and-Excitation –±–ª–æ–∫ –¥–ª—è –ø–µ—Ä–µ–≤–∑–≤–µ—à–∏–≤–∞–Ω–∏—è –∫–∞–Ω–∞–ª–æ–≤"""
    channels = input_tensor.shape[-1]
    se = GlobalAveragePooling2D()(input_tensor)
    se = Reshape((1, 1, channels))(se)
    se = Dense(channels//config.se_reduction, activation='swish',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(se)
    se = Dense(channels, activation='sigmoid',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(se)
    return Multiply()([input_tensor, se])

def residual_block(x, filters, stride=1):
    """–û—Å—Ç–∞—Ç–æ—á–Ω—ã–π –±–ª–æ–∫ —Å SE-–º–æ–¥—É–ª–µ–º"""
    shortcut = x
    if stride != 1 or shortcut.shape[-1] != filters:
        shortcut = Conv2D(filters, (1,1), strides=stride,
                          kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(shortcut)
        shortcut = BatchNormalization()(shortcut)
    
    x = Conv2D(filters, (3,3), strides=stride, padding='same',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(x)
    x = BatchNormalization()(x)
    x = Activation('swish')(x)
    x = Conv2D(filters, (3,3), padding='same',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(x)
    x = BatchNormalization()(x)
    x = se_block(x)
    return Activation('swish')(Add()([x, shortcut]))

# ====================== –ü–û–°–¢–†–û–ï–ù–ò–ï –ú–û–î–ï–õ–ò ======================
def build_model(num_classes):
    """–°–±–æ—Ä–∫–∞ –ø–æ–ª–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏"""
    inputs = Input(shape=config.input_shape)
    
    # –ë—ç–∫–±–æ–Ω CNN
    x = Conv2D(64, (7,7), strides=2, padding='same',
               kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(inputs)
    x = BatchNormalization()(x)
    x = Activation('swish')(x)
    x = MaxPooling2D((3,3), strides=2, padding='same')(x)
    
    # Residual Blocks
    x = residual_block(x, 64)
    x = residual_block(x, 128, stride=2)
    x = residual_block(x, 256, stride=2)
    x = residual_block(x, 512, stride=2)
    
    # –ì–æ–ª–æ–≤–Ω–∞—è —á–∞—Å—Ç—å
    x = GlobalAveragePooling2D()(x)
    x = LayerNormalization()(x)
    x = Dense(1024, activation='swish',
              kernel_regularizer=l1_l2(config.l1_value, config.l2_value))(x)
    x = Dropout(config.dropout_rate)(x)
    x = MoE(config.num_experts, config.expert_units)(x)
    
    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)
    
    # –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
    model = Model(inputs, outputs, name='AnimeClassifier')
    optimizer = SGD(learning_rate=config.initial_learning_rate,
                    momentum=0.9, nesterov=True)
    model.compile(optimizer=optimizer,
                  loss=focal_loss,
                  metrics=['accuracy', 'top_k_categorical_accuracy'])
    return model

# ====================== –û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• ======================
def create_dataset(subset):
    """–°–æ–∑–¥–∞–µ—Ç tf.data.Dataset –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏"""
    return tf.keras.utils.image_dataset_from_directory(
        config.source_dir,
        labels='inferred',
        label_mode='categorical',
        color_mode='rgb',
        batch_size=config.batch_size,
        image_size=config.input_shape[:2],
        validation_split=config.validation_split,
        subset=subset,
        seed=config.augment_seed,
        shuffle=(subset == 'training')
    )
   

class EpochSpacingCallback(Callback):
    """–í–∏–∑—É–∞–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –ª–æ–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è"""
    def on_epoch_end(self, epoch, logs=None):
        print('\n' + '=' * 100 + '\n')

def plot_images(ds, train_ds_raw, num_images=30, filename='samples.png', cols=5):
    rows = math.ceil(num_images / cols)  # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫
    plt.figure(figsize=(cols * 5, rows * 5))  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ

    for i, (image, label) in enumerate(ds.take(num_images)):
        image = image[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –±–∞—Ç—á–∞
        plt.subplot(rows, cols, i + 1)  # –†–∞–∑–º–µ—â–∞–µ–º –ø–æ —Å—Ç—Ä–æ–∫–∞–º –∏ –∫–æ–ª–æ–Ω–∫–∞–º
        plt.imshow((image * 255.0).numpy().astype('uint8'))  # –î–µ–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è uint8
        plt.title(train_ds_raw.class_names[label.numpy().argmax()], fontsize=18)
        plt.axis('off')

    plt.tight_layout()  # –£–±–∏—Ä–∞–µ–º –Ω–∞–ª–æ–∂–µ–Ω–∏–µ
    plt.savefig(filename)
    plt.close()

# ====================== –û–ë–£–ß–ï–ù–ò–ï –ú–û–î–ï–õ–ò ======================
def run_training():
    """–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–µ–π"""
    os.makedirs(os.path.dirname(config.checkpoint_path), exist_ok=True)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    train_ds_raw = create_dataset('training')
    val_ds_raw = create_dataset('validation')
    num_classes = len(train_ds_raw.class_names)

    # –°—Ç–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ (–æ–±—â–∞—è –¥–ª—è train/val)
    def static_preprocessing(image, label):
        #–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        image = tf.cast(image, tf.float32) / 255.0
        return image, label

    # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    augmentations = tf.keras.Sequential([
        RandomRotation(config.rotation_range),
        RandomZoom(config.zoom_range),
        RandomContrast(config.contrast_range),
        RandomBrightness(config.brightness_range),
        tf.keras.layers.RandomFlip(
            mode='horizontal_and_vertical' if config.horizontal_flip and config.vertical_flip else
            'horizontal' if config.horizontal_flip else
            'vertical' if config.vertical_flip else None
        )
    ])

    # –ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    train_ds = (
        train_ds_raw
        .map(lambda x, y: (augmentations(x, training=True), y), num_parallel_calls=tf.data.AUTOTUNE)
        .map(static_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)
        .prefetch(tf.data.AUTOTUNE)
    )

    # –ü–∞–π–ø–ª–∞–π–Ω –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    val_ds = (
        val_ds_raw
        .map(static_preprocessing, num_parallel_calls=tf.data.AUTOTUNE)
        .prefetch(tf.data.AUTOTUNE)
    )

    # –≤—ã–≤–æ–¥ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    plot_images(train_ds, train_ds_raw, filename='train_samples.png', cols=5)
    plot_images(val_ds, train_ds_raw, filename='val_samples.png', cols=5)

    # –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ (—Å—á–∏—Ç–∞–µ–º –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö)
    labels = np.concatenate([y.numpy().argmax(axis=1) for x, y in train_ds_raw], axis=0)
    class_weights = compute_class_weight("balanced", classes=np.unique(labels), y=labels)
    class_weights_dict = {i: w for i, w in enumerate(class_weights)}

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    if os.path.exists(config.checkpoint_path):
        print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        model = load_model(
            config.checkpoint_path,
            custom_objects={
                'MoE': MoE,
                'focal_loss': focal_loss,
                'LayerNormalization': LayerNormalization
            }
        )
        if model.output_shape[-1] != num_classes:
            raise ValueError(f"–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ {model.output_shape[-1]} –∫–ª–∞—Å—Å–æ–≤, –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç {num_classes}")
    else:
        print("–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –º–æ–¥–µ–ª–∏...")
        model = build_model(num_classes)
        model.summary()

    # –ö–æ–ª–±—ç–∫–∏
    callbacks = [
        ReduceLROnPlateau(monitor='val_loss', factor=config.reduce_lr_factor,
                         patience=config.reduce_lr_patience, min_lr=config.min_learning_rate),
        ModelCheckpoint(config.checkpoint_path, save_best_only=True, monitor='val_loss'),
        EarlyStopping(monitor='val_loss', patience=config.early_stopping_patience,
                     restore_best_weights=True),
        EpochSpacingCallback()
    ]

    # –û–±—É—á–µ–Ω–∏–µ
    history = model.fit(
        train_ds,
        validation_data=val_ds,
        epochs=config.epochs,
        callbacks=callbacks,
        class_weight=class_weights_dict
    )
    return model

# ====================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ======================
def save_labels():
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤"""
    class_names = sorted(os.listdir(config.source_dir))
    with open(config.labels_path, "w") as f:
        for label in class_names: f.write(label + "\n")
    print(f"–ú–µ—Ç–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {config.labels_path}")

def convert_to_onnx():
    """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –≤ ONNX —Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö"""
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = load_model(
        config.checkpoint_path,
        custom_objects={
            'MoE': MoE,
            'focal_loss': focal_loss,
            'LayerNormalization': LayerNormalization
        }
    )

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ ONNX
    input_signature = [tf.TensorSpec(shape=[None, *config.input_shape], dtype=tf.float32)]
    tf2onnx.convert.from_keras(model, input_signature=input_signature, output_path=config.onnx_path)
    save_labels()

    print("–º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")

    check_onnx_work()

def check_onnx_work():
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤
    train_ds = tf.keras.utils.image_dataset_from_directory(
        config.source_dir,
        image_size=config.input_shape[:2],
        batch_size=config.batch_size,
        shuffle=False
    )
    class_names = train_ds.class_names
    with open(config.labels_path, 'w') as f:
        f.write('\n'.join(class_names))

    # –ó–∞–≥—Ä—É–∑–∫–∞ ONNX –º–æ–¥–µ–ª–∏
    session = ort.InferenceSession(config.onnx_path)
    input_name = session.get_inputs()[0].name

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –ø–∞–ø–∫–µ
    img_path = "test.jpg"

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞
    img = tf.keras.preprocessing.image.load_img(img_path)
    img_array = tf.keras.preprocessing.image.img_to_array(img)

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –±–∞—Ç—á–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
    img_array = tf.expand_dims(img_array, 0) / 255.0 # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è [0,1]
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
    print(f"\nüîç –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_path}")
    print(f"–§–æ—Ä–º–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {img_array.shape}")

    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    results = session.run(None, {input_name: img_array.numpy().astype(np.float32)})
    probabilities = results[0][0]
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    top5_indices = np.argsort(probabilities)[::-1][:5]
    top5_classes = [class_names[i] for i in top5_indices]
    top5_probs = [probabilities[i] for i in top5_indices]

    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüîÆ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ onnx:")
    for cls, prob in zip(top5_classes, top5_probs):
        print(f"  {cls}: {prob*100:.2f}%")

    model = load_model(
        config.checkpoint_path,
        custom_objects={
            'MoE': MoE,
            'focal_loss': focal_loss,
            'LayerNormalization': LayerNormalization
        }
    )

    results = model.predict(img_array)

    probabilities = results[0]
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–ø-5 –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    top5_indices = np.argsort(probabilities)[::-1][:5]
    top5_classes = [class_names[i] for i in top5_indices]
    top5_probs = [probabilities[i] for i in top5_indices]

    print("\nüîÆ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ keras:")
    for cls, prob in zip(top5_classes, top5_probs):
        print(f"  {cls}: {prob*100:.2f}%")

# ====================== –ò–ù–¢–ï–†–§–ï–ô–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ======================
def main():
    """–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –ø—Ä–æ–≥—Ä–∞–º–º—ã"""
    while True:
        print("\n–ú–µ–Ω—é:")
        print("1. –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
        print("2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ ONNX")
        print("3. –¢–µ—Å—Ç ONNX")
        print("exit. –í—ã—Ö–æ–¥")
        choice = input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ: ").strip()
        
        if choice == '1':
            if not os.path.exists(config.source_dir):
                print("–û—à–∏–±–∫–∞: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                continue
            run_training()
            print("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        elif choice == '2':
            if not os.path.exists(config.checkpoint_path):
                print("–û—à–∏–±–∫–∞: –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
                continue
            convert_to_onnx()
        elif choice == '3':
            check_onnx_work()
        elif choice == 'exit':
            print("–í—ã—Ö–æ–¥...")
            break
        else:
            print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥!")

if __name__ == "__main__":
    main()